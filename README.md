# Russian HellaSwag

The [HellaSwag](https://rowanzellers.com/hellaswag/) benchmark was proposed by Zellers, Rowan, Holtzman, Bisk, Farhadi, Choi, and Yejin in 2019 in the [HellaSwag paper](https://arxiv.org/abs/1905.07830). HellaSwag is a benchmark that assess common sense sentence-completion amongst Large Language Models (LLMs).

This repo contains a pipeline to generate a Russian-language translation of the [HellaSwag dataset](https://huggingface.co/datasets/Rowan/hellaswag). The resultant dataset is available on [Hugging Face]() and may be used to assess common sense sentence completion abilities of Russian-langauge models.
