{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29467e94",
   "metadata": {},
   "source": [
    "# Translating the HellaSwag Dataset to Russian\n",
    "\n",
    "The goal of this notebook is to translate the [HellaSwag dataset](https://huggingface.co/datasets/Rowan/hellaswag) to Russian. See [README.md](../README.md) for more information about the HellaSwag benchmark, and how it can be used to assess common-sense sentence-completion in Large Language Models (LLMs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065288de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the datasets lib\n",
    "%pip install datasets huggingface_hub[hf_xet] ipywidgets --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9bc545a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull the dataset from hugging face hub\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"Rowan/hellaswag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90e5daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cool to see that hellaswag already supports the new, more efficient xet file storage\n",
    "# read more about xet here: https://huggingface.co/blog/xet-on-the-hub\n",
    "\n",
    "# let's have a look at a few sample from the hellaswag dataset\n",
    "sample = dataset[\"train\"][0]\n",
    "print(\"Context (ctx):\", sample[\"ctx\"])\n",
    "print(\"\\nEndings:\", sample[\"endings\"])\n",
    "print(\"\\nLabel (correct ending index):\", sample[\"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9bf434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out the features of the dataset\n",
    "print(\"Features:\", dataset[\"train\"].features)\n",
    "\n",
    "# check number of rows for each split\n",
    "print(\"Train samples:\", len(dataset[\"train\"]))\n",
    "print(\"Validation samples:\", len(dataset[\"validation\"]))\n",
    "print(\"Test samples:\", len(dataset[\"test\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d0ed85",
   "metadata": {},
   "source": [
    "## Using Open Source Translation\n",
    "\n",
    "For this exercise, we'll use the [Opus MT](https://huggingface.co/Helsinki-NLP/opus-mt-en-ru) translation model from the [University of Helsinki NLP department](https://huggingface.co/Helsinki-NLP).\n",
    "\n",
    "Once we've translated the data, we'll revisit it with human annotators to confirm its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d73f68f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# install additional libs\n",
    "%pip install transformers sentencepiece --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc1ab2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "import torch\n",
    "\n",
    "# load model and tokenizer\n",
    "model_name = \"Helsinki-NLP/opus-mt-en-ru\"\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "# use gpu if possible (this increases the speed of translation)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
